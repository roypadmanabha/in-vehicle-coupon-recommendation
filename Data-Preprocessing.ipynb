{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2a04635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d8d8c",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7cacd752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>passanger</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>coupon</th>\n",
       "      <th>expiration</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <th>CarryAway</th>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>55</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Restaurant(&lt;20)</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Carry out &amp; Take away</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       destination  passanger weather  temperature  time  \\\n",
       "0  No Urgent Place      Alone   Sunny           55   2PM   \n",
       "1  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "2  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "3  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "4  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "\n",
       "                  coupon expiration  gender age      maritalStatus  ...  \\\n",
       "0        Restaurant(<20)         1d  Female  21  Unmarried partner  ...   \n",
       "1           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "2  Carry out & Take away         2h  Female  21  Unmarried partner  ...   \n",
       "3           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "4           Coffee House         1d  Female  21  Unmarried partner  ...   \n",
       "\n",
       "   CoffeeHouse CarryAway RestaurantLessThan20 Restaurant20To50  \\\n",
       "0        never       NaN                  4~8              1~3   \n",
       "1        never       NaN                  4~8              1~3   \n",
       "2        never       NaN                  4~8              1~3   \n",
       "3        never       NaN                  4~8              1~3   \n",
       "4        never       NaN                  4~8              1~3   \n",
       "\n",
       "  toCoupon_GEQ5min toCoupon_GEQ15min toCoupon_GEQ25min direction_same  \\\n",
       "0                1                 0                 0              0   \n",
       "1                1                 0                 0              0   \n",
       "2                1                 1                 0              0   \n",
       "3                1                 1                 0              0   \n",
       "4                1                 1                 0              0   \n",
       "\n",
       "  direction_opp  Y  \n",
       "0             1  1  \n",
       "1             1  0  \n",
       "2             1  1  \n",
       "3             1  0  \n",
       "4             1  0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('in-vehicle-coupon-recommendation.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ab9dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Points:  12684\n",
      "Number of features:  26\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The attributes of data:  ['destination' 'passanger' 'weather' 'temperature' 'time' 'coupon'\n",
      " 'expiration' 'gender' 'age' 'maritalStatus' 'has_children' 'education'\n",
      " 'occupation' 'income' 'car' 'Bar' 'CoffeeHouse' 'CarryAway'\n",
      " 'RestaurantLessThan20' 'Restaurant20To50' 'toCoupon_GEQ5min'\n",
      " 'toCoupon_GEQ15min' 'toCoupon_GEQ25min' 'direction_same' 'direction_opp'\n",
      " 'Y']\n"
     ]
    }
   ],
   "source": [
    "print('Number of Data Points: ', data.shape[0])\n",
    "print('Number of features: ', data.shape[1])\n",
    "print('-'*100)\n",
    "print('The attributes of data: ', data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "541c41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users that are accepted the coupon is  7210 , 56.843 %\n",
      "The number of users that are rejected the coupon is  5474 , 43.157 %\n"
     ]
    }
   ],
   "source": [
    "Y_value_counts = data.groupby('Y').Y.count()\n",
    "print('The number of users that are accepted the coupon is ',Y_value_counts[1],',',round(Y_value_counts[1]/data.shape[0]*100,3),'%')\n",
    "print('The number of users that are rejected the coupon is ',Y_value_counts[0],',',round(Y_value_counts[0]/data.shape[0]*100,3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee703f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d50548",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca80ee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12610, 26)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "duplicate = data[data.duplicated(keep = 'last')]\n",
    "# duplicate.shape #(74, 26)\n",
    "data = data.drop_duplicates()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208ddf2",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9d54f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present or not? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>12502</td>\n",
       "      <td>99.143537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bar</th>\n",
       "      <td>107</td>\n",
       "      <td>0.848533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <td>217</td>\n",
       "      <td>1.720856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CarryAway</th>\n",
       "      <td>150</td>\n",
       "      <td>1.189532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <td>129</td>\n",
       "      <td>1.022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <td>189</td>\n",
       "      <td>1.498810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      missing_count  missing_percentage\n",
       "car                           12502           99.143537\n",
       "Bar                             107            0.848533\n",
       "CoffeeHouse                     217            1.720856\n",
       "CarryAway                       150            1.189532\n",
       "RestaurantLessThan20            129            1.022998\n",
       "Restaurant20To50                189            1.498810"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "print('Is there any missing value present or not?',data.isnull().values.any())\n",
    "missing_percentage = data.isnull().sum()*100/len(data)\n",
    "missing_value_df = pd.DataFrame({'missing_count': data.isnull().sum(),'missing_percentage': missing_percentage})\n",
    "missing_value_df[missing_value_df.missing_count != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60731ee",
   "metadata": {},
   "source": [
    "- Feature 'car' has 99% of the missing value, drop this feature because even after predicting missing values, this feature has less importance, and it has less predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85e562cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['car'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e785ff",
   "metadata": {},
   "source": [
    "### Correlation of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5ad2363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>has_children</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.157089</td>\n",
       "      <td>-0.227165</td>\n",
       "      <td>0.097972</td>\n",
       "      <td>-0.097972</td>\n",
       "      <td>0.059393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_children</th>\n",
       "      <td>-0.018599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079434</td>\n",
       "      <td>-0.010773</td>\n",
       "      <td>-0.032353</td>\n",
       "      <td>0.032353</td>\n",
       "      <td>-0.045056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <td>-0.157089</td>\n",
       "      <td>0.079434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.321260</td>\n",
       "      <td>-0.302066</td>\n",
       "      <td>0.302066</td>\n",
       "      <td>-0.082693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <td>-0.227165</td>\n",
       "      <td>-0.010773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.189900</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>-0.108139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_same</th>\n",
       "      <td>0.097972</td>\n",
       "      <td>-0.032353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.302066</td>\n",
       "      <td>-0.189900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.014932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_opp</th>\n",
       "      <td>-0.097972</td>\n",
       "      <td>0.032353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302066</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.059393</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.082693</td>\n",
       "      <td>-0.108139</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>-0.014932</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   temperature  has_children  toCoupon_GEQ5min  \\\n",
       "temperature           1.000000     -0.018599               NaN   \n",
       "has_children         -0.018599      1.000000               NaN   \n",
       "toCoupon_GEQ5min           NaN           NaN               NaN   \n",
       "toCoupon_GEQ15min    -0.157089      0.079434               NaN   \n",
       "toCoupon_GEQ25min    -0.227165     -0.010773               NaN   \n",
       "direction_same        0.097972     -0.032353               NaN   \n",
       "direction_opp        -0.097972      0.032353               NaN   \n",
       "Y                     0.059393     -0.045056               NaN   \n",
       "\n",
       "                   toCoupon_GEQ15min  toCoupon_GEQ25min  direction_same  \\\n",
       "temperature                -0.157089          -0.227165        0.097972   \n",
       "has_children                0.079434          -0.010773       -0.032353   \n",
       "toCoupon_GEQ5min                 NaN                NaN             NaN   \n",
       "toCoupon_GEQ15min           1.000000           0.321260       -0.302066   \n",
       "toCoupon_GEQ25min           0.321260           1.000000       -0.189900   \n",
       "direction_same             -0.302066          -0.189900        1.000000   \n",
       "direction_opp               0.302066           0.189900       -1.000000   \n",
       "Y                          -0.082693          -0.108139        0.014932   \n",
       "\n",
       "                   direction_opp         Y  \n",
       "temperature            -0.097972  0.059393  \n",
       "has_children            0.032353 -0.045056  \n",
       "toCoupon_GEQ5min             NaN       NaN  \n",
       "toCoupon_GEQ15min       0.302066 -0.082693  \n",
       "toCoupon_GEQ25min       0.189900 -0.108139  \n",
       "direction_same         -1.000000  0.014932  \n",
       "direction_opp           1.000000 -0.014932  \n",
       "Y                      -0.014932  1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr() # Co-variance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c23cf6",
   "metadata": {},
   "source": [
    "1.Feature â€˜direction_sameâ€™ is perfectly correlated with â€˜direction_oppâ€™, both have the same variance.\n",
    "\n",
    "2.â€˜toCoupon_GEQ5minâ€™ feature has no correlation with any feature because it has the same value â€˜1â€™ for all data points, which means all the restaurants/bars are at least more than five minutes away from the driver.\n",
    "\n",
    "So, drop both 'direction_opp' and 'toCoupon_GEQ5min' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a3cd3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12610, 23)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['direction_opp', 'toCoupon_GEQ5min'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4801b800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>has_children</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12610.000000</td>\n",
       "      <td>12610.000000</td>\n",
       "      <td>12610.000000</td>\n",
       "      <td>12610.000000</td>\n",
       "      <td>12610.000000</td>\n",
       "      <td>12610.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.267248</td>\n",
       "      <td>0.414512</td>\n",
       "      <td>0.559794</td>\n",
       "      <td>0.116019</td>\n",
       "      <td>0.215543</td>\n",
       "      <td>0.567565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.153386</td>\n",
       "      <td>0.492657</td>\n",
       "      <td>0.496432</td>\n",
       "      <td>0.320260</td>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.495434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature  has_children  toCoupon_GEQ15min  toCoupon_GEQ25min  \\\n",
       "count  12610.000000  12610.000000       12610.000000       12610.000000   \n",
       "mean      63.267248      0.414512           0.559794           0.116019   \n",
       "std       19.153386      0.492657           0.496432           0.320260   \n",
       "min       30.000000      0.000000           0.000000           0.000000   \n",
       "25%       55.000000      0.000000           0.000000           0.000000   \n",
       "50%       80.000000      0.000000           1.000000           0.000000   \n",
       "75%       80.000000      1.000000           1.000000           0.000000   \n",
       "max       80.000000      1.000000           1.000000           1.000000   \n",
       "\n",
       "       direction_same             Y  \n",
       "count    12610.000000  12610.000000  \n",
       "mean         0.215543      0.567565  \n",
       "std          0.411215      0.495434  \n",
       "min          0.000000      0.000000  \n",
       "25%          0.000000      0.000000  \n",
       "50%          0.000000      1.000000  \n",
       "75%          0.000000      1.000000  \n",
       "max          1.000000      1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947207a",
   "metadata": {},
   "source": [
    "### Analysis of 'direction_same' attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3257ca3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction_same</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>Total_%</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>Rejected</th>\n",
       "      <th>%Accepted</th>\n",
       "      <th>%Rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9892</td>\n",
       "      <td>78.446</td>\n",
       "      <td>5576</td>\n",
       "      <td>4316</td>\n",
       "      <td>56.369</td>\n",
       "      <td>43.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2718</td>\n",
       "      <td>21.554</td>\n",
       "      <td>1581</td>\n",
       "      <td>1137</td>\n",
       "      <td>58.168</td>\n",
       "      <td>41.832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   direction_same  Total_Count  Total_%  Accepted  Rejected  %Accepted  \\\n",
       "0               0         9892   78.446      5576      4316     56.369   \n",
       "1               1         2718   21.554      1581      1137     58.168   \n",
       "\n",
       "   %Rejected  \n",
       "0     43.631  \n",
       "1     41.832  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysis of 'direction_same' feature\n",
    "df = pd.DataFrame(sorted(list(data['direction_same'].unique())),columns=['direction_same'])\n",
    "df['Total_Count'] = list(data.groupby('direction_same').Y.count())\n",
    "df['Total_%'] = round(df['Total_Count']/data['direction_same'].shape[0]*100,3)\n",
    "df['Accepted'] = list(data[data.Y==1].groupby('direction_same').Y.count())\n",
    "df['Rejected'] = list(data[data.Y==0].groupby('direction_same').Y.count())\n",
    "df['%Accepted'] = round(df['Accepted']/df['Total_Count']*100,3)\n",
    "df['%Rejected'] = round(df['Rejected']/df['Total_Count']*100,3)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44fd3fe",
   "metadata": {},
   "source": [
    "- direction_same feature has 78% value is '0', and 22% value is '1'. Both value has almost similar acceptance ratio. so this feature not more usefull. So, drop 'direction_same' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39168e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12610, 22)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['direction_same'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41620311",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "563586b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Y'], axis=1)\n",
    "y = data['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70c6c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10088, 21) (10088,)\n",
      "(2522, 21) (2522,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e48076b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10088 entries, 10387 to 9948\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   destination           10088 non-null  object\n",
      " 1   passanger             10088 non-null  object\n",
      " 2   weather               10088 non-null  object\n",
      " 3   temperature           10088 non-null  int64 \n",
      " 4   time                  10088 non-null  object\n",
      " 5   coupon                10088 non-null  object\n",
      " 6   expiration            10088 non-null  object\n",
      " 7   gender                10088 non-null  object\n",
      " 8   age                   10088 non-null  object\n",
      " 9   maritalStatus         10088 non-null  object\n",
      " 10  has_children          10088 non-null  int64 \n",
      " 11  education             10088 non-null  object\n",
      " 12  occupation            10088 non-null  object\n",
      " 13  income                10088 non-null  object\n",
      " 14  Bar                   9999 non-null   object\n",
      " 15  CoffeeHouse           9917 non-null   object\n",
      " 16  CarryAway             9961 non-null   object\n",
      " 17  RestaurantLessThan20  9981 non-null   object\n",
      " 18  Restaurant20To50      9939 non-null   object\n",
      " 19  toCoupon_GEQ15min     10088 non-null  int64 \n",
      " 20  toCoupon_GEQ25min     10088 non-null  int64 \n",
      "dtypes: int64(4), object(17)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae11a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present or not? True\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing value present or not?',X_train.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39b918e",
   "metadata": {},
   "source": [
    "# Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3937720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode imputation for missing values in train data\n",
    "X_train['Bar'] = X_train['Bar'].fillna(X_train['Bar'].value_counts().index[0])\n",
    "X_train['CoffeeHouse'] = X_train['CoffeeHouse'].fillna(X_train['CoffeeHouse'].value_counts().index[0])\n",
    "X_train['CarryAway'] = X_train['CarryAway'].fillna(X_train['CarryAway'].value_counts().index[0])\n",
    "X_train['RestaurantLessThan20'] = X_train['RestaurantLessThan20'].fillna(X_train['RestaurantLessThan20'].value_counts().index[0])\n",
    "X_train['Restaurant20To50'] = X_train['Restaurant20To50'].fillna(X_train['Restaurant20To50'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f528ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode imputation for missing values in test data\n",
    "X_test['Bar'] = X_test['Bar'].fillna(X_train['Bar'].value_counts().index[0])\n",
    "X_test['CoffeeHouse'] = X_test['CoffeeHouse'].fillna(X_train['CoffeeHouse'].value_counts().index[0])\n",
    "X_test['CarryAway'] = X_test['CarryAway'].fillna(X_train['CarryAway'].value_counts().index[0])\n",
    "X_test['RestaurantLessThan20'] = X_test['RestaurantLessThan20'].fillna(X_train['RestaurantLessThan20'].value_counts().index[0])\n",
    "X_test['Restaurant20To50'] = X_test['Restaurant20To50'].fillna(X_train['Restaurant20To50'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4293fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present in X_train? False\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing value present in X_train?',X_train.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9aae2983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present in X_test? False\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing value present in X_test?',X_test.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa030821",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c986bc0",
   "metadata": {},
   "source": [
    "#### FE -- to_Coupon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba73a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [0 2 1]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    10088.000000\n",
       "mean         0.673672\n",
       "std          0.670863\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          2.000000\n",
       "Name: to_Coupon, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- to_Coupon is combination of two features, toCoupon_GEQ15min and toCoupon_GEQ25min\n",
    "to_Coupon = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    if (list(X_train['toCoupon_GEQ15min'])[i] == 0):\n",
    "        to_Coupon.append(0)\n",
    "    elif (list(X_train['toCoupon_GEQ15min'])[i] == 1)and(list(X_train['toCoupon_GEQ25min'])[i] == 0):\n",
    "        to_Coupon.append(1)\n",
    "    else:\n",
    "        to_Coupon.append(2)\n",
    "        \n",
    "X_train['to_Coupon'] = to_Coupon\n",
    "print('Unique values:',X_train['to_Coupon'].unique())\n",
    "print('-'*50)\n",
    "X_train['to_Coupon'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b97ee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [1 0 2]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2522.000000\n",
       "mean        0.684377\n",
       "std         0.675039\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         2.000000\n",
       "Name: to_Coupon, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- to_Coupon is combination of two features, toCoupon_GEQ15min and toCoupon_GEQ25min\n",
    "to_Coupon = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    if (list(X_test['toCoupon_GEQ15min'])[i] == 0):\n",
    "        to_Coupon.append(0)\n",
    "    elif (list(X_test['toCoupon_GEQ15min'])[i] == 1)and(list(X_test['toCoupon_GEQ25min'])[i] == 0):\n",
    "        to_Coupon.append(1)\n",
    "    else:\n",
    "        to_Coupon.append(2)\n",
    "        \n",
    "X_test['to_Coupon'] = to_Coupon\n",
    "print('Unique values:',X_test['to_Coupon'].unique())\n",
    "print('-'*50)\n",
    "X_test['to_Coupon'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf00c3",
   "metadata": {},
   "source": [
    "#### FE--coupon_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6976a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['4~8' '1~3' 'less1' 'never' 'gt8']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     10088\n",
       "unique        5\n",
       "top         1~3\n",
       "freq       3110\n",
       "Name: coupon_freq, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- coupon_freq is combination of five features, RestaurantLessThan20, CoffeeHouse, CarryAway, Bar, Restaurant20To50\n",
    "coupon_freq = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    if (list(X_train['coupon'])[i] == 'Restaurant(<20)'):\n",
    "        coupon_freq.append(list(X_train['RestaurantLessThan20'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Coffee House'):\n",
    "        coupon_freq.append(list(X_train['CoffeeHouse'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Carry out & Take away'):\n",
    "        coupon_freq.append(list(X_train['CarryAway'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Bar'):\n",
    "        coupon_freq.append(list(X_train['Bar'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Restaurant(20-50)'):\n",
    "        coupon_freq.append(list(X_train['Restaurant20To50'])[i])\n",
    "        \n",
    "X_train['coupon_freq'] = coupon_freq\n",
    "print('Unique values:',X_train['coupon_freq'].unique())\n",
    "print('-'*50)\n",
    "X_train['coupon_freq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3c188ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['less1' '1~3' '4~8' 'never' 'gt8']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     2522\n",
       "unique       5\n",
       "top        1~3\n",
       "freq       760\n",
       "Name: coupon_freq, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- coupon_freq is combination of five features, RestaurantLessThan20, CoffeeHouse, CarryAway, Bar, Restaurant20To50\n",
    "coupon_freq = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    if (list(X_test['coupon'])[i] == 'Restaurant(<20)'):\n",
    "        coupon_freq.append(list(X_test['RestaurantLessThan20'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Coffee House'):\n",
    "        coupon_freq.append(list(X_test['CoffeeHouse'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Carry out & Take away'):\n",
    "        coupon_freq.append(list(X_test['CarryAway'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Bar'):\n",
    "        coupon_freq.append(list(X_test['Bar'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Restaurant(20-50)'):\n",
    "        coupon_freq.append(list(X_test['Restaurant20To50'])[i])\n",
    "        \n",
    "X_test['coupon_freq'] = coupon_freq\n",
    "print('Unique values:',X_test['coupon_freq'].unique()) \n",
    "print('-'*50)\n",
    "X_test['coupon_freq'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dacefd",
   "metadata": {},
   "source": [
    "#### FE -- occupation_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c2054577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          10088\n",
       "unique            25\n",
       "top       Unemployed\n",
       "freq            1484\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['occupation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95f9cd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['Low_Acceptance' 'Medium_Acceptance' 'High_Acceptance'\n",
      " 'Medium_Low_Acceptance' 'Medium_High_Acceptance']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                     10088\n",
       "unique                        5\n",
       "top       Medium_Low_Acceptance\n",
       "freq                       2635\n",
       "Name: occupation_class, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# occupation feature has 25 no of distinct values, which creates very sparsity in data after Encoding\n",
    "# FE -- occupation_class where categorize all occupation in its suitable class.\n",
    "occupation_dict = {'Healthcare Support':'High_Acceptance','Construction & Extraction':'High_Acceptance','Healthcare Practitioners & Technical':'High_Acceptance',\n",
    "                   'Protective Service':'High_Acceptance','Architecture & Engineering':'High_Acceptance','Production Occupations':'Medium_High_Acceptance',\n",
    "                    'Student':'Medium_High_Acceptance','Office & Administrative Support':'Medium_High_Acceptance','Transportation & Material Moving':'Medium_High_Acceptance',\n",
    "                    'Building & Grounds Cleaning & Maintenance':'Medium_High_Acceptance','Management':'Medium_Acceptance','Food Preparation & Serving Related':'Medium_Acceptance',\n",
    "                   'Life Physical Social Science':'Medium_Acceptance','Business & Financial':'Medium_Acceptance','Computer & Mathematical':'Medium_Acceptance',\n",
    "                    'Sales & Related':'Medium_Low_Acceptance','Personal Care & Service':'Medium_Low_Acceptance','Unemployed':'Medium_Low_Acceptance',\n",
    "                   'Farming Fishing & Forestry':'Medium_Low_Acceptance','Installation Maintenance & Repair':'Medium_Low_Acceptance','Education&Training&Library':'Low_Acceptance',\n",
    "                    'Arts Design Entertainment Sports & Media':'Low_Acceptance','Community & Social Services':'Low_Acceptance','Legal':'Low_Acceptance','Retired':'Low_Acceptance'}\n",
    "# occupation_dict\n",
    "X_train['occupation_class'] = X_train['occupation'].map(occupation_dict)\n",
    "print('Unique values:',X_train['occupation_class'].unique())\n",
    "print('-'*50)\n",
    "X_train['occupation_class'].describe()\n",
    "# X_train['occupation_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b748f781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           2522\n",
       "unique            25\n",
       "top       Unemployed\n",
       "freq             377\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['occupation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "40f4b5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['Low_Acceptance' 'Medium_Acceptance' 'Medium_Low_Acceptance'\n",
      " 'Medium_High_Acceptance' 'High_Acceptance']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                      2522\n",
       "unique                        5\n",
       "top       Medium_Low_Acceptance\n",
       "freq                        665\n",
       "Name: occupation_class, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# occupation feature has 25 no of distinct values, which creates very sparsity in data after Encoding\n",
    "# FE -- occupation_class where categorize all occupation in its suitable class.\n",
    "occupation_dict = {'Healthcare Support':'High_Acceptance','Construction & Extraction':'High_Acceptance','Healthcare Practitioners & Technical':'High_Acceptance',\n",
    "                   'Protective Service':'High_Acceptance','Architecture & Engineering':'High_Acceptance','Production Occupations':'Medium_High_Acceptance',\n",
    "                    'Student':'Medium_High_Acceptance','Office & Administrative Support':'Medium_High_Acceptance','Transportation & Material Moving':'Medium_High_Acceptance',\n",
    "                    'Building & Grounds Cleaning & Maintenance':'Medium_High_Acceptance','Management':'Medium_Acceptance','Food Preparation & Serving Related':'Medium_Acceptance',\n",
    "                   'Life Physical Social Science':'Medium_Acceptance','Business & Financial':'Medium_Acceptance','Computer & Mathematical':'Medium_Acceptance',\n",
    "                    'Sales & Related':'Medium_Low_Acceptance','Personal Care & Service':'Medium_Low_Acceptance','Unemployed':'Medium_Low_Acceptance',\n",
    "                   'Farming Fishing & Forestry':'Medium_Low_Acceptance','Installation Maintenance & Repair':'Medium_Low_Acceptance','Education&Training&Library':'Low_Acceptance',\n",
    "                    'Arts Design Entertainment Sports & Media':'Low_Acceptance','Community & Social Services':'Low_Acceptance','Legal':'Low_Acceptance','Retired':'Low_Acceptance'}\n",
    "# occupation_dict\n",
    "X_test['occupation_class'] = X_test['occupation'].map(occupation_dict)\n",
    "print('Unique values:',X_test['occupation_class'].unique())\n",
    "print('-'*50)\n",
    "X_test['occupation_class'].describe()\n",
    "# X_test['occupation_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee0bfa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (10088, 16) \n",
      "X_test: (2522, 16)\n",
      "--------------------------------------------------\n",
      "['destination' 'passanger' 'weather' 'temperature' 'time' 'coupon'\n",
      " 'expiration' 'gender' 'age' 'maritalStatus' 'has_children' 'education'\n",
      " 'income' 'to_Coupon' 'coupon_freq' 'occupation_class']\n"
     ]
    }
   ],
   "source": [
    "# After Feature Engineering, removing unwanted features\n",
    "X_train = X_train.drop(['toCoupon_GEQ15min','toCoupon_GEQ25min','Bar','CoffeeHouse','CarryAway','RestaurantLessThan20','Restaurant20To50','occupation'], axis=1)\n",
    "X_test = X_test.drop(['toCoupon_GEQ15min','toCoupon_GEQ25min','Bar','CoffeeHouse','CarryAway','RestaurantLessThan20','Restaurant20To50','occupation'], axis=1)\n",
    "print('X_train:',X_train.shape,'\\nX_test:',X_test.shape)\n",
    "print('-'*50)\n",
    "print(X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd3cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bcb8c6c",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15381e2b",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bff2f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [['Work','Home','No Urgent Place'],['Kid(s)','Alone','Partner','Friend(s)'],['Rainy','Snowy','Sunny'],[30,55,80],['7AM','10AM','2PM','6PM','10PM'],\n",
    "         ['Bar','Restaurant(20-50)','Coffee House','Restaurant(<20)','Carry out & Take away'],['2h','1d'],['Female','Male'],['below21','21','26','31','36','41','46','50plus'],\n",
    "         ['Widowed','Divorced','Married partner','Unmarried partner','Single'],\n",
    "         ['Some High School','High School Graduate','Some college - no degree','Associates degree','Bachelors degree','Graduate degree (Masters or Doctorate)'],\n",
    "         ['Less than $12500','$12500 - $24999','$25000 - $37499','$37500 - $49999','$50000 - $62499','$62500 - $74999','$75000 - $87499','$87500 - $99999','$100000 or More'],\n",
    "         ['never','less1','1~3','4~8','gt8'],['Low_Acceptance','Medium_Low_Acceptance','Medium_Acceptance','Medium_High_Acceptance','High_Acceptance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d93b910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_Ordinal_encoding: (10088, 16)\n"
     ]
    }
   ],
   "source": [
    "Ordinal_enc = OrdinalEncoder(categories=order)\n",
    "X_train_Ordinal_encoding = Ordinal_enc.fit_transform(X_train.drop(['has_children','to_Coupon'], axis=1)) # 'has_children' and 'to_Coupon' are numeric features\n",
    "\n",
    "X_train_Ordinal_encoding = pd.DataFrame(X_train_Ordinal_encoding,columns=['destination','passanger','weather','temperature','time','coupon','expiration',\n",
    "                                                                          'gender','age','maritalStatus','education','income','coupon_freq','occupation_class'])\n",
    "\n",
    "X_train_Ordinal_encoding['has_children'] = X_train['has_children']\n",
    "X_train_Ordinal_encoding['to_Coupon'] = X_train['to_Coupon']\n",
    "\n",
    "print('X_train_Ordinal_encoding:',X_train_Ordinal_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf20f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_Ordinal_encoding: (2522, 16)\n"
     ]
    }
   ],
   "source": [
    "Ordinal_enc = OrdinalEncoder(categories=order)\n",
    "X_test_Ordinal_encoding = Ordinal_enc.fit_transform(X_test.drop(['has_children','to_Coupon'], axis=1)) # 'has_children' and 'to_Coupon' are numeric features\n",
    "\n",
    "X_test_Ordinal_encoding = pd.DataFrame(X_test_Ordinal_encoding,columns=['destination','passanger','weather','temperature','time','coupon','expiration',\n",
    "                                                                        'gender','age','maritalStatus','education','income','coupon_freq','occupation_class'])\n",
    "\n",
    "X_test_Ordinal_encoding['has_children'] = X_test['has_children']\n",
    "X_test_Ordinal_encoding['to_Coupon'] = X_test['to_Coupon']\n",
    "\n",
    "print('X_test_Ordinal_encoding:',X_test_Ordinal_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20068f6b",
   "metadata": {},
   "source": [
    "### Frequency Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "690defc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_enc(column_name,X):\n",
    "  \"\"\"It returns Frequency encoded feature\"\"\"\n",
    "  return X[column_name].map(X.groupby(column_name).size()/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b6d1fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_frequency_encoding: (10088, 16)\n"
     ]
    }
   ],
   "source": [
    "X_train_frequency_encoding = pd.DataFrame()\n",
    "for i in range(X_train.shape[1]):\n",
    "  X_train_frequency_encoding[X_train.columns.values[i]+'_freq_enc'] = frequency_enc(X_train.columns.values[i],X_train)\n",
    "\n",
    "print('X_train_frequency_encoding:',X_train_frequency_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0dca13e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_frequency_encoding: (2522, 16)\n"
     ]
    }
   ],
   "source": [
    "X_test_frequency_encoding = pd.DataFrame()\n",
    "for i in range(X_test.shape[1]):\n",
    "  X_test_frequency_encoding[X_test.columns.values[i]+'_freq_enc'] = frequency_enc(X_test.columns.values[i],X_test)\n",
    "\n",
    "print('X_test_frequency_encoding:',X_test_frequency_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563726f",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24531a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_target_encoding: (10088, 16)\n"
     ]
    }
   ],
   "source": [
    "def target_enc(column_name,X):\n",
    "  \"\"\"It returns Target encoded feature for train data\"\"\"\n",
    "  X['Y_train'] = y_train\n",
    "  return X[column_name].map(X.groupby(column_name)['Y_train'].mean())\n",
    "\n",
    "X_train_target_encoding = pd.DataFrame()\n",
    "for i in range(X_train.shape[1]):\n",
    "  X_train_target_encoding[X_train.columns.values[i]+'_target_enc'] = target_enc(X_train.columns.values[i],X_train)\n",
    "\n",
    "print('X_train_target_encoding:',X_train_target_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c569d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_target_encoding: (2522, 16)\n"
     ]
    }
   ],
   "source": [
    "def target_enc(column_name,X):\n",
    "  \"\"\"It returns Target encoded feature for test data\"\"\"\n",
    "  X['Y_test'] = y_test\n",
    "  return X[column_name].map(X.groupby(column_name)['Y_test'].mean())\n",
    "\n",
    "X_test_target_encoding = pd.DataFrame()\n",
    "for i in range(X_test.shape[1]):\n",
    "  X_test_target_encoding[X_test.columns.values[i]+'_target_enc'] = target_enc(X_test.columns.values[i],X_test)\n",
    "\n",
    "print('X_test_target_encoding:',X_test_target_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef992ed",
   "metadata": {},
   "source": [
    "### Response Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64975ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response encoding function\n",
    "def response_coding(feature,X,Y):\n",
    "    \"\"\"It returns Response encoded feature\"\"\"\n",
    "    X[feature] = X[feature].str.replace('~','_')\n",
    "    X[feature] = X[feature].str.replace('[^a-zA-Z0-9_ ]',' ')\n",
    "    X[feature] = X[feature].str.replace(' +',' ')\n",
    "    X[feature] = X[feature].str.strip()\n",
    "    X[feature] = X[feature].str.replace(' ','_')\n",
    "    X[feature] = X[feature].str.lower()\n",
    "    response_code_0 = [];response_code_1 = []\n",
    "    unique_cat_features = X[feature].unique()\n",
    "    unique_cat_features = np.sort(unique_cat_features)\n",
    "    for i in range(len(unique_cat_features)):\n",
    "        total_count = X[feature][(X[feature] == unique_cat_features[i])].count()\n",
    "        p0 = (X[feature][((X[feature] == unique_cat_features[i]) & (Y==0))].count())/total_count\n",
    "        p1 = (X[feature][((X[feature] == unique_cat_features[i]) & (Y==1))].count())/total_count\n",
    "        response_code_0.append(p0);response_code_1.append(p1)\n",
    "    dict_response_code_0 = dict(zip(unique_cat_features, response_code_0))\n",
    "    dict_response_code_1 = dict(zip(unique_cat_features, response_code_1))\n",
    "    X_response_0 = X[feature].map(dict_response_code_0)\n",
    "    X_response_1 = X[feature].map(dict_response_code_1)\n",
    "    X_response_0 = X_response_0.values.reshape(-1,1)\n",
    "    X_response_1 = X_response_1.values.reshape(-1,1)\n",
    "    return X_response_0,X_response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c6e3f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_destination_0,X_train_destination_1 = response_coding('destination',X_train,y_train)\n",
    "X_train_passanger_0,X_train_passanger_1 = response_coding('passanger',X_train,y_train)\n",
    "X_train_weather_0,X_train_weather_1 = response_coding('weather',X_train,y_train)\n",
    "X_train_time_0,X_train_time_1 = response_coding('time',X_train,y_train)\n",
    "X_train_coupon_0,X_train_coupon_1 = response_coding('coupon',X_train,y_train)\n",
    "X_train_expiration_0,X_train_expiration_1 = response_coding('expiration',X_train,y_train)\n",
    "X_train_gender_0,X_train_gender_1 = response_coding('gender',X_train,y_train)\n",
    "X_train_age_0,X_train_age_1 = response_coding('age',X_train,y_train)\n",
    "X_train_maritalStatus_0,X_train_maritalStatus_1 = response_coding('maritalStatus',X_train,y_train)\n",
    "X_train_education_0,X_train_education_1 = response_coding('education',X_train,y_train)\n",
    "X_train_income_0,X_train_income_1 = response_coding('income',X_train,y_train)\n",
    "X_train_coupon_freq_0,X_train_coupon_freq_1 = response_coding('coupon_freq',X_train,y_train)\n",
    "X_train_occupation_class_0,X_train_occupation_class_1 = response_coding('occupation_class',X_train,y_train)\n",
    "\n",
    "X_test_destination_0,X_test_destination_1 = response_coding('destination',X_test,y_test)\n",
    "X_test_passanger_0,X_test_passanger_1 = response_coding('passanger',X_test,y_test)\n",
    "X_test_weather_0,X_test_weather_1 = response_coding('weather',X_test,y_test)\n",
    "X_test_time_0,X_test_time_1 = response_coding('time',X_test,y_test)\n",
    "X_test_coupon_0,X_test_coupon_1 = response_coding('coupon',X_test,y_test)\n",
    "X_test_expiration_0,X_test_expiration_1 = response_coding('expiration',X_test,y_test)\n",
    "X_test_gender_0,X_test_gender_1 = response_coding('gender',X_test,y_test)\n",
    "X_test_age_0,X_test_age_1 = response_coding('age',X_test,y_test)\n",
    "X_test_maritalStatus_0,X_test_maritalStatus_1 = response_coding('maritalStatus',X_test,y_test)\n",
    "X_test_education_0,X_test_education_1 = response_coding('education',X_test,y_test)\n",
    "X_test_income_0,X_test_income_1 = response_coding('income',X_test,y_test)\n",
    "X_test_coupon_freq_0,X_test_coupon_freq_1 = response_coding('coupon_freq',X_test,y_test)\n",
    "X_test_occupation_class_0,X_test_occupation_class_1 = response_coding('occupation_class',X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8ed83d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of numerical features\n",
    "def norm(column_name,X):\n",
    "    \"\"\"It returns Normalized feature\"\"\"\n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(X[column_name].values.reshape(1,-1))\n",
    "    X_norm = normalizer.transform(X[column_name].values.reshape(1,-1))\n",
    "    return X_norm.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a267fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temperature_norm = norm('temperature',X_train)\n",
    "X_train_has_children_norm = norm('has_children',X_train)\n",
    "X_train_to_Coupon_norm = norm('to_Coupon',X_train)\n",
    "\n",
    "X_test_temperature_norm = norm('temperature',X_test)\n",
    "X_test_has_children_norm = norm('has_children',X_test)\n",
    "X_test_to_Coupon_norm = norm('to_Coupon',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1e3a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_response_encoding: (10088, 29) \n",
      "X_test_response_encoding: (2522, 29)\n"
     ]
    }
   ],
   "source": [
    "X_train_response_encoding = np.hstack((X_train_destination_0,X_train_destination_1,X_train_passanger_0,X_train_passanger_1,X_train_weather_0,X_train_weather_1,X_train_time_0,X_train_time_1,X_train_coupon_0,X_train_coupon_1,X_train_expiration_0,X_train_expiration_1,X_train_gender_0,X_train_gender_1,X_train_age_0,X_train_age_1,X_train_maritalStatus_0,X_train_maritalStatus_1,X_train_education_0,X_train_education_1,X_train_income_0,X_train_income_1,X_train_coupon_freq_0,X_train_coupon_freq_1,X_train_occupation_class_0,X_train_occupation_class_1,X_train_temperature_norm,X_train_has_children_norm,X_train_to_Coupon_norm))\n",
    "X_test_response_encoding = np.hstack((X_test_destination_0,X_test_destination_1,X_test_passanger_0,X_test_passanger_1,X_test_weather_0,X_test_weather_1,X_test_time_0,X_test_time_1,X_test_coupon_0,X_test_coupon_1,X_test_expiration_0,X_test_expiration_1,X_test_gender_0,X_test_gender_1,X_test_age_0,X_test_age_1,X_test_maritalStatus_0,X_test_maritalStatus_1,X_test_education_0,X_test_education_1,X_test_income_0,X_test_income_1,X_test_coupon_freq_0,X_test_coupon_freq_1,X_test_occupation_class_0,X_test_occupation_class_1,X_test_temperature_norm,X_test_has_children_norm,X_test_to_Coupon_norm))\n",
    "print('X_train_response_encoding:',X_train_response_encoding.shape,'\\nX_test_response_encoding:',X_test_response_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd7b31",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "478a2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding function\n",
    "def ohe(column_name,X):\n",
    "    \"\"\"It returns One hot encoded feature in X data\"\"\"  \n",
    "    X[column_name] = X[column_name].str.replace('~','_')\n",
    "    X[column_name] = X[column_name].str.replace('[^a-zA-Z0-9_ ]',' ')\n",
    "    X[column_name] = X[column_name].str.replace(' +',' ')\n",
    "    X[column_name] = X[column_name].str.strip()\n",
    "    X[column_name] = X[column_name].str.replace(' ','_')\n",
    "    X[column_name] = X[column_name].str.lower()\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    return vectorizer.fit_transform(X[column_name].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "018434de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_destination_ohe = ohe('destination',X_train)\n",
    "X_train_passanger_ohe = ohe('passanger',X_train)\n",
    "X_train_weather_ohe = ohe('weather',X_train)\n",
    "X_train_time_ohe = ohe('time',X_train)\n",
    "X_train_coupon_ohe = ohe('coupon',X_train)\n",
    "X_train_expiration_ohe = ohe('expiration',X_train)\n",
    "X_train_gender_ohe = ohe('gender',X_train)\n",
    "X_train_age_ohe = ohe('age',X_train)\n",
    "X_train_maritalStatus_ohe = ohe('maritalStatus',X_train)\n",
    "X_train_education_ohe = ohe('education',X_train)\n",
    "X_train_income_ohe = ohe('income',X_train)\n",
    "X_train_coupon_freq_ohe = ohe('coupon_freq',X_train)\n",
    "X_train_occupation_class_ohe = ohe('occupation_class',X_train)\n",
    "\n",
    "X_test_destination_ohe = ohe('destination',X_test)\n",
    "X_test_passanger_ohe = ohe('passanger',X_test)\n",
    "X_test_weather_ohe = ohe('weather',X_test)\n",
    "X_test_time_ohe = ohe('time',X_test)\n",
    "X_test_coupon_ohe = ohe('coupon',X_test)\n",
    "X_test_expiration_ohe = ohe('expiration',X_test)\n",
    "X_test_gender_ohe = ohe('gender',X_test)\n",
    "X_test_age_ohe = ohe('age',X_test)\n",
    "X_test_maritalStatus_ohe = ohe('maritalStatus',X_test)\n",
    "X_test_education_ohe = ohe('education',X_test)\n",
    "X_test_income_ohe = ohe('income',X_test)\n",
    "X_test_coupon_freq_ohe = ohe('coupon_freq',X_test)\n",
    "X_test_occupation_class_ohe = ohe('occupation_class',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5116c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of numerical features\n",
    "def norm(column_name,X):\n",
    "    \"\"\"It returns Normalized feature\"\"\"\n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(X[column_name].values.reshape(1,-1))\n",
    "    X_norm = normalizer.transform(X[column_name].values.reshape(1,-1))\n",
    "    return X_norm.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e02236b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temperature_norm = norm('temperature',X_train)\n",
    "X_train_has_children_norm = norm('has_children',X_train)\n",
    "X_train_to_Coupon_norm = norm('to_Coupon',X_train)\n",
    "\n",
    "X_test_temperature_norm = norm('temperature',X_test)\n",
    "X_test_has_children_norm = norm('has_children',X_test)\n",
    "X_test_to_Coupon_norm = norm('to_Coupon',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3fd0cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_ohe: (10088, 65) \n",
      "X_test_ohe: (2522, 65)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_train_ohe = hstack((X_train_destination_ohe, X_train_passanger_ohe, X_train_weather_ohe, X_train_time_ohe, X_train_coupon_ohe, X_train_expiration_ohe, X_train_gender_ohe, X_train_age_ohe, X_train_maritalStatus_ohe, X_train_education_ohe, X_train_income_ohe, X_train_coupon_freq_ohe, X_train_occupation_class_ohe, X_train_temperature_norm, X_train_has_children_norm, X_train_to_Coupon_norm)).tocsr()\n",
    "X_test_ohe = hstack((X_test_destination_ohe, X_test_passanger_ohe, X_test_weather_ohe, X_test_time_ohe, X_test_coupon_ohe, X_test_expiration_ohe, X_test_gender_ohe, X_test_age_ohe, X_test_maritalStatus_ohe, X_test_education_ohe, X_test_income_ohe, X_test_coupon_freq_ohe, X_test_occupation_class_ohe, X_test_temperature_norm, X_test_has_children_norm, X_test_to_Coupon_norm)).tocsr()\n",
    "print('X_train_ohe:',X_train_ohe.shape,'\\nX_test_ohe:',X_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f247f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
